{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de librerías ⬇️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.tree import export_text, plot_tree\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "random_state = 42\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar data de un csv\n",
    "df = pd.read_csv('../data/los_data_gt_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dtypes = df.dtypes\n",
    "\n",
    "# Iterate through each column dtype and change dtype to \"category\" if it's \"object\"\n",
    "for col_name, dtype in column_dtypes.items():\n",
    "    if dtype == 'object':\n",
    "        df[col_name] = df[col_name].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the encoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Reshape the input data to a 2-dimensional array\n",
    "data = df[['causa_atencion', 'municipio']]  # Selecting the columns you want to encode\n",
    "data = data.values  # No need to reshape as we have multiple columns\n",
    "\n",
    "# Fit and transform the encoder on the reshaped data\n",
    "encoded_data = encoder.fit_transform(data)\n",
    "\n",
    "# Assign the encoded data back to the DataFrame\n",
    "df[['causa_atencion', 'municipio']] = encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de Utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estMetrics(est, X, y):\n",
    "\n",
    "    y_pred = est.predict(X)\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "\n",
    "    # Calculate R-squared (R^2)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"R-squared (R^2): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateAndTestRegressor(X_train, X_test, y_train, y_test):\n",
    "    est = HistGradientBoostingRegressor(categorical_features=\"from_dtype\", random_state=random_state)\n",
    "    est.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Performance Metrics on Test Set:\")\n",
    "    estMetrics(est, X_test, y_test)\n",
    "\n",
    "    print(\"\\nPerformance Metrics on Train Set:\")\n",
    "    estMetrics(est, X_train, y_train)\n",
    "\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TuneAndTestRegressor(X_train, X_test, y_train, y_test):\n",
    "    param_grid = {\n",
    "        'max_depth': range(5, 16, 5),  # Maximum depth of each tree\n",
    "        'learning_rate': [0.01, 0.1, 0.2],  # Learning rate shrinks the contribution of each tree\n",
    "        'max_iter': [100, 200, 300],  # Maximum number of boosting iterations\n",
    "        'loss': ['squared_error', 'absolute_error', 'gamma', 'poisson']\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "\n",
    "    model = HistGradientBoostingRegressor(categorical_features=\"from_dtype\", random_state=random_state)\n",
    "\n",
    "    est = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        return_train_score=True,\n",
    "        cv=cv,\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters For Regressor:\", est.best_params_)\n",
    "    print()\n",
    "\n",
    "    print(\"Performance Metrics on Test Set:\")\n",
    "    estMetrics(est, X_test, y_test)\n",
    "\n",
    "    print(\"\\nPerformance Metrics on Train Set:\")\n",
    "    estMetrics(est, X_train, y_train)\n",
    "\n",
    "    return est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera Iteración de Modelo de Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación del Conjunto de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2228328, 10)\n",
      "(2228328,)\n"
     ]
    }
   ],
   "source": [
    "df_cp = df.copy()\n",
    "\n",
    "# Separate the target variable 'dias_estancia' into y and the rest of the DataFrame into X\n",
    "y = df_cp.pop('dias_estancia')\n",
    "X = df_cp\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1782662, 10)\n",
      "(1782662,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo y Métricas Iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como regla general, los algoritmos de ML basados en árboles no requieren de normalización/scaling de datos numéricos, pero sí requieren de codificación de las variables categoricas. La decisión de qué tipo de codificación usar se basó en la documentación de Gradient Boosting Trees de scikit-learn, donde se obtuvo que la codificación ordinal nativa de HistGradientBoosting es superior en cuanto a error medio y tiempo de entrenamiento en comparación con otros tipos de codificación como One Hot. (https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_categorical.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics on Test Set:\n",
      "Mean Squared Error (MSE): 5.8924\n",
      "Mean Absolute Error (MAE): 0.9843\n",
      "R-squared (R^2): 0.1067\n",
      "\n",
      "Performance Metrics on Train Set:\n",
      "Mean Squared Error (MSE): 5.7957\n",
      "Mean Absolute Error (MAE): 0.9807\n",
      "R-squared (R^2): 0.1145\n"
     ]
    }
   ],
   "source": [
    "est = CreateAndTestRegressor(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters For Regressor: {'learning_rate': 0.2, 'loss': 'poisson', 'max_depth': 5, 'max_iter': 300}\n",
      "\n",
      "Performance Metrics on Test Set:\n",
      "Mean Squared Error (MSE): 5.8282\n",
      "Mean Absolute Error (MAE): 0.9640\n",
      "R-squared (R^2): 0.1164\n",
      "\n",
      "Performance Metrics on Train Set:\n",
      "Mean Squared Error (MSE): 5.6599\n",
      "Mean Absolute Error (MAE): 0.9557\n",
      "R-squared (R^2): 0.1352\n"
     ]
    }
   ],
   "source": [
    "est = TuneAndTestRegressor(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda Iteración de Modelo de Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación y Separación del Conjunto de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp = df.copy()\n",
    "\n",
    "df_cp.pop('municipio')\n",
    "df_cp.pop('region')\n",
    "df_cp = df_cp[df_cp['departamento'] == 'Guatemala']\n",
    "df_cp.pop('departamento')\n",
    "\n",
    "freqs = df_cp['dias_estancia'].value_counts()\n",
    "df_cp = df_cp.loc[df['dias_estancia'] <= 30]\n",
    "\n",
    "# Filter out the rows where the frequency is not equal to 1\n",
    "uniques = freqs[freqs == 1].index\n",
    "df_cp = df_cp[~df_cp['dias_estancia'].isin(uniques)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1190137, 7)\n",
      "(1190137,)\n"
     ]
    }
   ],
   "source": [
    "# Separate the target variable 'dias_estancia' into y and the rest of the DataFrame into X\n",
    "y = df_cp.pop('dias_estancia')\n",
    "X = df_cp\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(952109, 7)\n",
      "(952109,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo y Métricas Iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics on Test Set:\n",
      "Mean Squared Error (MSE): 4.4596\n",
      "Mean Absolute Error (MAE): 0.9525\n",
      "R-squared (R^2): 0.1296\n",
      "\n",
      "Performance Metrics on Train Set:\n",
      "Mean Squared Error (MSE): 4.5442\n",
      "Mean Absolute Error (MAE): 0.9572\n",
      "R-squared (R^2): 0.1362\n"
     ]
    }
   ],
   "source": [
    "est = CreateAndTestRegressor(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuneo de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters For Regressor: {'learning_rate': 0.1, 'loss': 'poisson', 'max_depth': 10, 'max_iter': 300}\n",
      "\n",
      "Performance Metrics on Test Set:\n",
      "Mean Squared Error (MSE): 4.4266\n",
      "Mean Absolute Error (MAE): 0.9385\n",
      "R-squared (R^2): 0.1360\n",
      "\n",
      "Performance Metrics on Train Set:\n",
      "Mean Squared Error (MSE): 4.4760\n",
      "Mean Absolute Error (MAE): 0.9401\n",
      "R-squared (R^2): 0.1492\n"
     ]
    }
   ],
   "source": [
    "est = TuneAndTestRegressor(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
